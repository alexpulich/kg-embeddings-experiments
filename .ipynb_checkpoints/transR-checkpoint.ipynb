{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import scipy.spatial.distance\n",
    "import operator\n",
    "import numpy as np\n",
    "import pprint\n",
    "from wikidata.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikidata client which allows to query wikidata and get a title of the passed entity, etc\n",
    "client = Client()\n",
    "\n",
    "#path to the projects with datasets and models dirs without a trailing slash\n",
    "PROJECT_DIR = '/Users/alexp/wrk/kgemb'\n",
    "\n",
    "#set the dimension of embeddings and the model used\n",
    "KG_DIMENSION = 100\n",
    "MODEL = 'transR' #could be transH as well ?\n",
    "\n",
    "#nothing to change\n",
    "ENTITY_EMBEDDING = PROJECT_DIR + '/models/' + MODEL + '/' + str(KG_DIMENSION) + '/entity2vec.vec'\n",
    "RELATION_EMBEDDING = PROJECT_DIR + '/models/' + MODEL + '/' + str(KG_DIMENSION) + '/relation2vec.vec'\n",
    "MATRIX = PROJECT_DIR + '/models/' + MODEL + '/' + str(KG_DIMENSION) + '/A.vec'\n",
    "\n",
    "ENTITY2ID = PROJECT_DIR + '/datasets/entity2id.txt'\n",
    "RELATION2ID = PROJECT_DIR + '/datasets/relation2id.txt'\n",
    "TRAIN2ID = PROJECT_DIR + '/datasets/train2id.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_ids = {\n",
    "    'Robert': 'Q12056060',\n",
    "    'Jon': 'Q3183235',\n",
    "    'Robb': 'Q13634884',\n",
    "    'Jaime': 'Q3806180',\n",
    "    'Cersei': 'Q3665163',\n",
    "    'Sansa': 'Q3472490',\n",
    "    'Joffrey': 'Q12900597',\n",
    "    'Tywin': 'Q12902445',\n",
    "    'Tyrion': 'Q2076759',\n",
    "    'Stannis': 'Q12056060',\n",
    "    'Catelyn': 'Q2941743', #not provided in the pretrained embeddings\n",
    "    'Bran': 'Q3643599',\n",
    "    'Arya': 'Q3624677',\n",
    "    'Ned': 'Q259818',\n",
    "    'Renly': 'Q18920105',\n",
    "    'Hound': 'Q3948140',\n",
    "    'Varys': 'Q4008842',\n",
    "    'Lysa': 'Q19791067',\n",
    "    'Tommen': 'Q19792294',\n",
    "#    'Pycelle': 'Maester Pycelle', #not provided in the pretrained embeddings\n",
    "    'Balon': 'Q23746101',\n",
    "    'Loras': 'Q18920137',\n",
    "    'Theon': 'Q1120793',\n",
    "    'Petyr': 'Q4360302',\n",
    "    'Edmure': 'Q23749012',\n",
    "    'Barristan': 'Q5721186',\n",
    "    'Roose': 'Q19799430',\n",
    "    'Margaery': 'Q12900933',\n",
    "    'Hoster': 'Q23730371',\n",
    "    'Myrcella': 'Q19799435'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_entities_ids():\n",
    "    \"\"\"\n",
    "    Save list of entities on which KG embeddings are trained\n",
    "    Using the index of element in this array we can retrieve\n",
    "    the coordinates of the vector from model.\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    with open(ENTITY2ID, 'r') as file:\n",
    "        entities_cnt = int(file.readline())\n",
    "        for _ in range(entities_cnt):\n",
    "            entities.append(file.readline().split('\\t')[0])\n",
    "    pickle.dump(entities, open(MODEL + '_entities.pickle', 'wb'))\n",
    "\n",
    "\n",
    "def dump_relations_ids():\n",
    "    \"\"\"\n",
    "    Save list of relations on which KG embeddings are trained\n",
    "    Using the index of element in this array we can retrieve\n",
    "    the coordinates of the vector from model.\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    with open(RELATION2ID, 'r') as file:\n",
    "        entities_cnt = int(file.readline())\n",
    "        for _ in range(entities_cnt):\n",
    "            entities.append(file.readline().split('\\t')[0])\n",
    "    pickle.dump(entities, open(MODEL + '_relation.pickle', 'wb'))\n",
    "\n",
    "\n",
    "def get_entity_embedding():\n",
    "    \"\"\"\n",
    "    Read embedding from file\n",
    "    :return: numpy.memmap\n",
    "    \"\"\"\n",
    "    return np.loadtxt(ENTITY_EMBEDDING)\n",
    "\n",
    "\n",
    "def get_relation_embedding():\n",
    "    \"\"\"\n",
    "    Read embedding from file\n",
    "    :return: numpy.memmap\n",
    "    \"\"\"\n",
    "    return np.loadtxt(RELATION_EMBEDDING)\n",
    "\n",
    "\n",
    "def get_vec_from_embedding(embedding, index):\n",
    "    \"\"\"\n",
    "    get the vector for embedding\n",
    "    :param embedding: numpy.memmap object with embedding\n",
    "    :param index: index of the required element\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return embedding[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not have to execute if there are entities.pickle and relations.pickle already\n",
    "dump_relations_ids()\n",
    "dump_entities_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_ids = pickle.load(open(MODEL + '_entities.pickle', 'rb'))\n",
    "relation_ids = pickle.load(open(MODEL + '_relation.pickle', 'rb'))\n",
    "matrix = np.loadtxt(MATRIX)\n",
    "\n",
    "entity_embedding = get_entity_embedding()\n",
    "relation_embedding = get_entity_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download labels for each relation from wikidata\n",
    "relation_labels = {}\n",
    "for relation in relation_ids:\n",
    "    relation_labels[relation] = str(client.get(relation).label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tywin = get_vec_from_embedding(entity_embedding, entities_ids.index(names_ids['Tywin']))\n",
    "tywin_matrix = get_vec_from_embedding(matrix, entities_ids.index(names_ids['Tywin']))\n",
    "jaime = get_vec_from_embedding(entity_embedding, entities_ids.index(names_ids['Jaime']))\n",
    "jaime_matrix = get_vec_from_embedding(matrix, entities_ids.index(names_ids['Jaime']))\n",
    "cersei = get_vec_from_embedding(entity_embedding, entities_ids.index(names_ids['Cersei']))\n",
    "cersei_matrix = get_vec_from_embedding(matrix, entities_ids.index(names_ids['Cersei']))\n",
    "father = get_vec_from_embedding(relation_embedding, relation_ids.index('P22'))\n",
    "mother = get_vec_from_embedding(relation_embedding, relation_ids.index('P25'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025467354481829997\n",
      "0.025285558446349995\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# if the relation between chosen entities is correct, head+relation-tail should tend to zero\n",
    "# or at least closer to zero than other relations\n",
    "print(np.mean(abs(tywin*tywin_matrix+father-jaime*jaime_matrix)))\n",
    "print(np.mean(abs(jaime*jaime_matrix+father-tywin*tywin_matrix)))\n",
    "\n",
    "print(np.mean(abs(jaime*jaime_matrix+father-tywin*tywin_matrix)) > np.mean(abs(jaime*jaime_matrix+mother-tywin*tywin_matrix)))\n",
    "print(np.mean(abs(tywin*tywin_matrix+father-jaime*jaime_matrix)) > np.mean(abs(tywin*tywin_matrix+mother-jaime*jaime_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first five items:\n",
      "[('place of death', 0.010780149672650001),\n",
      " ('named after', 0.01436815275057),\n",
      " ('participant of', 0.016830264063669997),\n",
      " ('medical condition', 0.020509286698489997),\n",
      " ('given name', 0.021314651194150006)]\n",
      "\n",
      "last five items:\n",
      "[('from fictional universe', 0.05534917011431),\n",
      " ('sexual orientation', 0.058503168988069995),\n",
      " ('country', 0.06328725118483),\n",
      " (\"topic's main category\", 0.06614846593307),\n",
      " ('partner', 0.06702763906555)]\n",
      "\n",
      "########\n",
      "\n",
      "first five items:\n",
      "[('place of death', 0.011403133205329999),\n",
      " ('named after', 0.01448901302655),\n",
      " ('participant of', 0.01691039182307),\n",
      " ('medical condition', 0.020579526169590003),\n",
      " ('given name', 0.02122639282465)]\n",
      "\n",
      "last five items:\n",
      "[('from fictional universe', 0.05562800876498999),\n",
      " ('sexual orientation', 0.05854643101193),\n",
      " ('country', 0.06331701534163),\n",
      " (\"topic's main category\", 0.06636317406693),\n",
      " ('partner', 0.06680780093444999)]\n"
     ]
    }
   ],
   "source": [
    "# experiments with the idea provided above\n",
    "\n",
    "rels = {}\n",
    "for relation in relation_ids:\n",
    "    rel = get_vec_from_embedding(relation_embedding, relation_ids.index(relation))\n",
    "    #rels[relation] = np.mean(abs(tywin+rel-jaime))\n",
    "    rels[relation_labels[relation]] = np.mean(abs(tywin*tywin_matrix+rel-jaime*jaime_matrix))\n",
    "    \n",
    "sorted_rels = sorted(rels.items(), key=operator.itemgetter(1))\n",
    "\n",
    "print('first five items:')\n",
    "pprint.pprint(sorted_rels[:5])\n",
    "print()\n",
    "print('last five items:')\n",
    "pprint.pprint(sorted_rels[-5:])\n",
    "\n",
    "\n",
    "print('\\n########\\n')\n",
    "\n",
    "\n",
    "rels = {}\n",
    "for relation in relation_ids:\n",
    "    rel = get_vec_from_embedding(relation_embedding, relation_ids.index(relation))\n",
    "    #rels[relation] = np.mean(abs(tywin+rel-jaime))\n",
    "    rels[relation_labels[relation]] = np.mean(abs(jaime*jaime_matrix+rel-tywin*tywin_matrix))\n",
    "    \n",
    "sorted_rels = sorted(rels.items(), key=operator.itemgetter(1))\n",
    "\n",
    "print('first five items:')\n",
    "pprint.pprint(sorted_rels[:5])\n",
    "print()\n",
    "print('last five items:')\n",
    "pprint.pprint(sorted_rels[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_triples = []\n",
    "with open(TRAIN2ID, 'r') as file:\n",
    "        triples_cnt = int(file.readline())\n",
    "        for _ in range(triples_cnt):\n",
    "            valid_triples.append(file.readline().split())\n",
    "\n",
    "success = []\n",
    "fail = []\n",
    "changed_list = []\n",
    "for index, triple in enumerate(valid_triples):\n",
    "    e1 = get_vec_from_embedding(entity_embedding, int(triple[0]))\n",
    "    e1_matrix = get_vec_from_embedding(matrix, int(triple[0]))\n",
    "    e2 = get_vec_from_embedding(entity_embedding, int(triple[1]))\n",
    "    e2_matrix = get_vec_from_embedding(matrix, int(triple[1]))\n",
    "    r = get_vec_from_embedding(relation_embedding, int(triple[2]))\n",
    "    r_mean = min_r = np.mean(abs(e1*e1_matrix+r-e2*e2_matrix))\n",
    "    min_r_vec = r\n",
    "    \n",
    "    for relation in relation_ids:\n",
    "        rel = get_vec_from_embedding(relation_embedding, relation_ids.index(relation))\n",
    "        curr_r = np.mean(abs(e1*e1_matrix+rel-e2*e2_matrix))\n",
    "        if curr_r < min_r:\n",
    "            min_r = curr_r\n",
    "            min_r_vec = rel\n",
    "    \n",
    "    \n",
    "    if np.array_equal(min_r_vec,r):\n",
    "        success.append(triple)\n",
    "    else:\n",
    "        fail.append(triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully predicted:\n",
      "Lancel Lannister - place of death - Great Sept of Baelor\n",
      "False\n",
      "The High Sparrow - place of death - Great Sept of Baelor\n",
      "False\n",
      "Margaery Tyrell - place of death - Great Sept of Baelor\n",
      "False\n",
      "Loras Tyrell - place of death - Great Sept of Baelor\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"Successfully predicted:\")\n",
    "for triple in success:\n",
    "    e1 = client.get(entities_ids[int(triple[0])]).label\n",
    "    e2 = client.get(entities_ids[int(triple[1])]).label\n",
    "    r = client.get(relation_ids[int(triple[2])]).label\n",
    "    print(f'{e1} - {r} - {e2}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
